\documentclass[aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{fontspec}
\usepackage{adjustbox}
\usepackage[inkscapeversion=1.2]{svg}
\usepackage{fancyvrb}
\usetikzlibrary{shadings, shapes, arrows, shapes.geometric, arrows.meta, positioning, fit, backgrounds, calc}

\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% Define colors for clarity
\definecolor{docker}{RGB}{225,108,54}
\definecolor{slurm}{RGB}{63,81,181}
\definecolor{jupyter}{RGB}{239,108,0}
\definecolor{gpu}{RGB}{76,175,80}


% Define colors for visual distinction
\definecolor{cnode07color}{RGB}{210, 225, 240} % Light Blue
\definecolor{cnode08color}{RGB}{240, 210, 210} % Light Red
\definecolor{containercolor}{RGB}{255, 250, 205} % Light Yellow

\beamertemplatenavigationsymbolsempty

% Set the background color
% #000A1E
\definecolor{sitebackground1}{RGB}{0,10,30}
% #040714
\definecolor{sitebackground2}{RGB}{4,7,20}
% #66c6ea
\definecolor{logocolor}{RGB}{102,198,234}



\definecolor{darkblue}{RGB}{25,28,53}
\definecolor{baseblue}{RGB}{19,80,158}
\definecolor{additionalblue}{RGB}{47,127,193}

\definecolor{baselightblue}{RGB}{64,176,228}
\definecolor{additionallightblue}{RGB}{102,197,238}

\definecolor{baselightblue}{RGB}{64,176,228}

\setbeamercolor{background canvas}{bg=baseblue}

\setbeamercolor{normal text}{fg=white}
\setbeamercolor{title}{fg=white}
\setbeamercolor{frametitle}{fg=white}
\setbeamercolor{itemize item}{fg=logocolor}
\setbeamercolor{block title}{fg=logocolor}


% Load custom fonts
\newfontfamily\headerfont{Unageo}[
Path = ../fonts/,
Extension = .ttf,
UprightFont = *-Regular,
BoldFont = *-Bold,
ItalicFont = *-Regular-Italic,
]

\setsansfont{Montserrat}[
Path = ../fonts/,
Extension = .ttf,
UprightFont = *-Regular,
BoldFont = *-Bold,
ItalicFont = *-Italic,
]

% Set title and header font to Unageo
\setbeamerfont{title}{family=\headerfont, series=\bfseries}
\setbeamerfont{frametitle}{family=\headerfont, series=\bfseries}

% Command to easily adjust background images
\newcommand{\backgroundimages}[4]{%
	\begin{tikzpicture}[remember picture, overlay]
		% Left background image
		\node[anchor=south west, inner sep=0] at ([xshift=#1-0.3cm]current page.south west) 
		{\includesvg[width=0.3\paperwidth, height=0.3\paperheight]{#2}};
		
		% Right background image
		\node[anchor=north east, inner sep=0] at ([xshift=#1+0.3cm]current page.north east) 
		{\includesvg[width=0.3\paperwidth, height=0.3\paperheight]{#3}};
		
		% Center background image
		\node[anchor=south, inner sep=0] at ([xshift=#1-4cm]current page.south) 
		{\includesvg{#4}};
	\end{tikzpicture}%
}

\newcommand{\backgroundgradient}{%
	\begin{tikzpicture}[remember picture, overlay]		
		\node[anchor=south, inner sep=0] at ([xshift=-4cm]current page.south) 
		{\includesvg{Ellipse_4.svg}};
	\end{tikzpicture}%
}

\setbeamertemplate{background canvas}{
	\begin{tikzpicture}[remember picture, overlay]
		\shade[left color=baseblue, right color=darkblue] 
		(current page.south west) rectangle (current page.north east);
		
		\node[anchor=south west, inner sep=0] at ([xshift=-0.3cm]current page.south west) 
		{\includesvg[width=0.3\paperwidth, height=0.3\paperheight]{../img/Group_4.svg}};
		
		% Right background image
		\node[anchor=north east, inner sep=0] at ([xshift=0.3cm]current page.north east) 
		{\includesvg[width=0.3\paperwidth, height=0.3\paperheight]{../img/Group_5.svg}};
		
	\end{tikzpicture}
}

% Title page
\title{МАШИННОЕ ОБУЧЕНИЕ}
\subtitle{С СОВРЕМЕННЫМИ ПРИЛОЖЕНИЯМИ}
\author{Дмитрий Сергеевич Глызин}
\institute{Акселкомп / ЯрГУ}
%\date{\today}
\date{Весна 2026}

\begin{document}
	
	% First slide with title
	{
		%\setbeamertemplate{background}{
			%	\backgroundimages{0cm}{Group_4.svg}{Group_5.svg}{Ellipse_4.svg}
			%}
		\begin{frame}
			\titlepage
		\end{frame}
	}
	
	% Section slide
	\section{План курса}
	{
	
		\begin{frame}
			\frametitle{ПЛАН КУРСА}
			
			Раздел 1. Практикум по использованию больших языковых моделей
			\begin{itemize}
				\item [-] 1.1. Разработка c агентом-кодером
				\item [-] 1.2. Общение с LLM через OpenAI API
				\item [-] 1.3. Prompt Engineering - системный подход
				\item [-] 1.4. Создание агентов: цикл "рассуждение-действие"
				\item [-] 1.5. Retrieval Augmented Generation (RAG)
				\item [-] 1.5. Дообучение языковых моделей (Fine-Tuning)
			\end{itemize}
			
			
		\end{frame}
		
		\begin{frame}
			\frametitle{ПЛАН КУРСА}
						
			Раздел 2. Нейросети с PyTorch
			\begin{itemize}
				\item [-] 2.1. Тензоры PyTorch и автоматическое дифференцирование
				\item [-] 2.2. Нейросети. Обратное распространение ошибки
				\item [-] 2.3. Сверточные нейросети
				\item [-] 2.4. Архитектура трансформера (основание LLM)
				\item [-] 2.5. Оптимизация и регуляризация
			\end{itemize}
			
			Раздел 3. Классические алгоритмы машинного обучения
			\begin{itemize}
				\item [-] 3.1. Обучение "с учителем": классификация и регрессия
				\item [-] 3.2. Обучение "без учителя". Понижение размерности
				\item [-] 3.3. Оценивание и отбор моделей 
			\end{itemize}
			
		\end{frame}
    }	
	\section{Инфраструктура}	
	{

		% Section title slide
		\begin{frame}
			\centering
			\vspace{2cm}
			{\huge\headerfont\bfseries ИНФРАСТРУКТУРА}
		\end{frame}

	% Infra slide 1: Addresses and Linux commands
	\begin{frame}{ИНФРАСТРУКТУРА: АДРЕСА И КОМАНДЫ LINUX}
		%\frametitle
		
		{Адреса}
		\begin{itemize}
			\item [-] \textbf{Юпитерхаб:} \url{https://jupyterhub.yarsu.ru} (контейнеры на \texttt{cnode07})
			\item [-] \textbf{Управляющий узел (ssh):} \texttt{cnode07}
			\item [-] \textbf{Вычислительный узел:} \texttt{cnode08}
			\item [-] \texttt{cnode07}: \texttt{10.7.71.204} (внутри университетской сети)
			\item [-] \texttt{cnode08}: \texttt{10.7.71.203} (внутри университетской сети)
		\end{itemize}

		\bigskip
		%\frametitle
		{Команды Linux}
		\begin{itemize}
			\item [-] \texttt{ssh <user>@<host>} — ssh-доступ
			\item [-] \texttt{passwd} — смена пароля (только на \texttt{cnode07})
			\item [-] \texttt{nano <file>} — текстовый редактор
			\item [-] \texttt{cd <folder>} — переход в папку
			\item [-] \texttt{ls -la} — список файлов (включая скрытые)
			\item [-] стрелки вверх и вниз — история команд
			\item [-] \texttt{Tab} — подсказка по префиксу
		\end{itemize}
	\end{frame}

	% Infra slide 2: SLURM commands
	\begin{frame}{ИНФРАСТРУКТУРА: SLURM}
		
		%\frametitle
		{Команды SLURM}
		\begin{itemize}
			\item [-] \texttt{sinfo} — список ресурсов
			\item [-] \texttt{squeue} — список задач в очереди
			\item [-] \texttt{scancel <jobid>} — остановить задачу
			\item [-] \texttt{Ctrl+C} (два раза) — остановить интерактивную задачу
		\end{itemize}

		\bigskip
		%\frametitle
		{Примеры запуска задач}
		\begin{itemize}
			\item [-] \texttt{srun -w cnode07 hostname}
			\item [-] \texttt{srun -w cnode08 --gpus-per-task=1 nvidia-smi -L}
			\item [-] \texttt{srun -w cnode08 --gpus-per-task=2 \hspace{0.5mm} \\[-1mm]
				\hspace{1cm} sh /clusterhome/install/llamascripts/server\_qwen\_next\_1.sh}
		\end{itemize}
	\end{frame}

	\begin{frame}{ЗАПРОС ДЛЯ ДИАГРАММЫ}
		\begin{minipage}{\textwidth}
		\small
		Create a diagram in TeX, that should be added as a slide into beamer presentation, showing control flow for the following scenario:
		
		Slurm cluster consists of 2 nodes, cnode07 with 3x A30 gpus and cnode08 with 4xA100 gpus.
		
		On the cnode07 JupyterHub is running.
		
		User logs in to the JupyterHub and obtains a JupyterLab inside a docker container on cnode07. 
		
		JupyterLab is routed by JupyterHub and the user has it in his browser.
		
		Then in JuptyerLab he opens terminal and logs via ssh into cnode07 host.
		
		There he launches slurm job with llama.cpp server on cnode08:12434 serving Qwen Coder.
		
		Then in another terminal in jupterlab he runs Qwen-code CLI connected to this local llama.cpp server.
		\end{minipage}
	\end{frame}


	\begin{frame}{ДИАГРАММА ОТ Qwen3-235B-2507}
	\centering
	\begin{tikzpicture}[
		node distance=8mm,
		box/.style={draw, rounded corners, inner sep=6pt},
		service/.style={box, minimum height=12mm, text width=3.5cm, align=center},
		terminal/.style={box, draw=jupyter, text width=2.8cm, font=\ttfamily\small},
		ssh/.style={->, >=stealth, thick, orange, dashed},
		slurmjob/.style={->, >=stealth, thick, slurm, line width=1.5pt},
		browser/.style={circle, draw=jupyter, minimum size=8mm}
		]
		
		% ======== NODES ========
		% cnode07 (left)
		\node (cnode07) [service, fill=blue!5] {
			\textbf{cnode07} \\ 
			\footnotesize{3x A30 GPUs}
		};
		
		% Docker container inside cnode07
		\node (docker) [service, fill=docker!10, below=of cnode07, yshift=5mm] {
			\textbf{Docker Container} \\
			\footnotesize{JupyterHub Spawner}
		};
		
		% JupyterLab UI
		\node (jlab) [terminal, fill=white, above right=5mm and -5mm of docker] {
			\small\textcolor{jupyter}{\textbf{JupyterLab}} \\
			\footnotesize{(in browser)}
		};
		\node [browser] at (jlab.north west) [xshift=2mm, yshift=-2mm] {};
		
		% Terminals in JupyterLab
		\node (term1) [terminal, below=of jlab, yshift=-3mm] {
			\footnotesize{Terminal 1:} \\
			\texttt{\$ ssh cnode07}
		};
		\node (term2) [terminal, right=5mm of term1] {
			\footnotesize{Terminal 2:} \\
			\texttt{\$ qwen-cli ...}
		};
		
		% cnode08 (right)
		\node (cnode08) [service, fill=blue!5, right=4.5cm of cnode07] {
			\textbf{cnode08} \\ 
			\footnotesize{4x A100 GPUs}
		};
		
		% Llama.cpp server
		\node (llama) [terminal, fill=white, above=5mm of cnode08] {
			\small\textcolor{slurm}{\textbf{llama.cpp server}} \\
			\footnotesize{Qwen-Coder:12434}
		};
		
		% ======== CONNECTIONS ========
		% Browser to JupyterLab
		\draw [->, >=stealth, thick, jupyter] 
		(jlab.south) ++(0,-2mm) -- ++(0,-5mm) node[midway, right] {\scriptsize 1. User login};
		
		% Terminal 1: SSH to host
		\draw [ssh] (term1) -- ++(0,-8mm) -| 
		node[pos=0.7, below] {\scriptsize 2. Escape container} 
		(cnode07.south);
		
		% Slurm job launch
		\draw [slurmjob] (cnode07.east) -- ++(15mm,0) |- 
		node[pos=0.3, above] {\scriptsize 3. \texttt{srun llama-server}} 
		(llama.west);
		
		% CLI connection to server
		\draw [slurmjob] (term2.south) ++(0,-2mm) -- ++(0,-5mm) -| 
		node[pos=0.7, below] {\scriptsize 4. Connect to remote} 
		(llama.south);
		
		% ======== LABELS ========
		\node [anchor=north, font=\small\bfseries] at (cnode07.south) {Host OS};
		\node [anchor=north, font=\small\bfseries] at (docker.north) {JupyterHub};
		\node [anchor=south, font=\small, text=slurm] at (llama.north) {Slurm Job};
		
		% ======== LEGEND ========
		\begin{scope}[shift={(6,-2.5)}, font=\scriptsize]
			\node (sshicon) [circle, draw=orange, fill=orange!20, inner sep=1pt] {\tiny SSH};
			\node [right=2mm of sshicon] {Container escape};
			
			\node (slurmicon) [below=2mm of sshicon, circle, draw=slurm, fill=slurm!20, inner sep=1pt] {\tiny S};
			\node [right=2mm of slurmicon] {Slurm job};
		\end{scope}
		
	\end{tikzpicture}
	
	\vspace{3mm}
	\footnotesize
	\textbf{Sequence:} 
	1. User accesses JupyterLab via browser 
	$\rightarrow$ 
	2. SSH from container to host OS 
	$\rightarrow$ 
	3. Launch server on cnode08 via Slurm 
	$\rightarrow$ 
	4. CLI connects to remote server
\end{frame}


\begin{frame}{Control Flow: Distributed LLM Inference via Slurm}
	\centering
	\begin{tikzpicture}[
		node distance=8mm,
		box/.style={draw, rounded corners, inner sep=6pt},
		service/.style={box, minimum height=12mm, text width=3.5cm, align=center},
		terminal/.style={box, draw=jupyter, text width=2.8cm, font=\ttfamily\small},
		ssh/.style={->, >=stealth, thick, orange, dashed},
		slurmjob/.style={->, >=stealth, thick, slurm, line width=1.5pt},
		browser/.style={circle, draw=jupyter, minimum size=8mm}
		]
		
		% ======== NODES ========
		% cnode07 (left)
		\node (cnode07) [service, fill=blue!55] {
			\textbf{cnode07} \\ 
			\footnotesize{3x A30 GPUs}
		};
		
		% Docker container inside cnode07
		\node (docker) [service, fill=docker!64, below left=of cnode07, yshift=-1mm] {
			\textbf{Docker Container} 			
		};
		
		% JupyterLab UI
		\node (jlab) [terminal, fill=white, above=10mm of docker] {
			\small\textcolor{jupyter}{\textbf{JupyterLab}} \\
			\footnotesize{(in browser)}
		};
		
		\node (user) [browser] at (jlab.north) [xshift=0mm, yshift=16mm] {
			\textbf{user}
		};
		
		% Terminals in JupyterLab
		\node (term1) [terminal, right=of docker, yshift=0mm] {
			\footnotesize{Terminal 1:} \\
			\texttt{\$ ssh cnode07}
		};
		\node (term2) [terminal, right=5mm of term1] {
			\footnotesize{Terminal 2:} \\
			\texttt{\$ qwen}
		};
		
		% cnode08 (right)
		\node (cnode08) [service, fill=blue!55, right=of cnode07] {
			\textbf{cnode08} \\ 
			\footnotesize{4x A100 GPUs}
		};
		
		% Llama.cpp server
		\node (llama) [terminal, fill=white, above=5mm of cnode08] {
			\small\textcolor{slurm}{\textbf{llama.cpp Qwen Coder Next}} \\
			\footnotesize{cnode08:12434}
		};
		
		% ======== CONNECTIONS ========
		% Browser to JupyterLab
		\draw [->, >=stealth, thick, jupyter] 
		(user.south) ++(0,0mm) -- ++(0,-5mm) node[midway, right] {\scriptsize 1. User login};
		
		\draw [->, >=stealth, thick, jupyter] 
		(jlab.south) -- (docker.north) node[midway] {\scriptsize JupyterHub Spawner};
		
		
		% Terminal 1: SSH to host
		\draw [ssh] (term1.north) -- %++(0,-8mm) -| 
		node[midway] {\scriptsize 2. Escape container} 
		(cnode07.south);
		
		% Slurm job launch
		\draw [slurmjob] (cnode07) -- %++(15mm,0) |- 
		node[midway, xshift=-4mm, yshift=2mm] {\scriptsize 3. \texttt{srun llama-server}} 
		(llama.west);
		
		% CLI connection to server
		\draw [slurmjob] (term2.north) -- %++(0,-2mm) -- ++(0,-5mm) -| 
		node[pos=0.25, below] {\scriptsize 4. OpenAI API} 
		(llama.south);
		
		% ======== LABELS ========
		\node [anchor=south, font=\small\bfseries] at (cnode07.north) {Host OS};
		\node [anchor=south, font=\small\bfseries] at (jlab.north) {JupyterHub};
		\node [anchor=south, font=\small, text=slurm] at (llama.north) {Slurm Job};
		
		% ======== LEGEND ========
		\begin{scope}[shift={(-2,2.5)}, font=\scriptsize]
			\node (sshicon) [circle, draw=orange, fill=orange!20, inner sep=1pt] {\tiny SSH};
			\node [right=2mm of sshicon] {Container escape};
			
			\node (slurmicon) [below=2mm of sshicon, circle, draw=slurm, fill=slurm!20, inner sep=1pt] {\tiny S};
			\node [right=2mm of slurmicon] {Slurm job};
		\end{scope}
		
	\end{tikzpicture}
	
	\vspace{3mm}
	\footnotesize
	\textbf{Sequence:} 
	1. User accesses JupyterLab via browser 
	$\rightarrow$ 
	2. SSH from container to host OS 
	$\rightarrow$ 
	3. Launch server on cnode08 via Slurm 
	$\rightarrow$ 
	4. CLI connects to remote server
    \end{frame}
    }
    
    \begin{frame}{ИНФРАСТРУКТУРА: GIT И TEX}
    	
    	%\frametitle
    	{Команды git}
    	\begin{itemize}
    		\item [-] \texttt{git clone https://github.com/dglyzin/qwendiag.git} — клонируем репозиторий
    		\item [-] \texttt{git commit -a -m "update"} — фиксируем изменения
    		\item [-] \texttt{git add <filename>} — добавим файл под контроль версий
    		\item [-] \texttt{git checkout .} — отменим незафиксированные изменения
    		\item [-] \texttt{git push} — отправим зафиксированные изменения в репозиторий
    		\item [-] \texttt{git diff} — посмотрим, что было изменено после фиксации	
    	\end{itemize}
    
        {Команды TeX}
        \begin{itemize}
    	\item [-] \texttt{pdflatex <filename.tex>} — компилируем tex-файл в pdf
        \end{itemize}
    
    \end{frame}
    
    \begin{frame}{ЧТО НЕ ТАК С ЗАПРОСОМ ДЛЯ ДИАГРАММЫ?}
    \begin{itemize}
    	\item [-] можно ли улучшить сам запрос для более качественного предварительного результата?
    	\item [-] как итеративно улучшить (а не ухудшить) предварительный результат дополнительными запросами?
    \end{itemize}
    
    \end{frame}

    \section{1.1. Разработка c агентом-кодером}
    {
    \begin{frame}
        \centering
        \vspace{2cm}
	    {\huge\headerfont\bfseries 1.1. РАЗРАБОТКА С АГЕНТОМ-КОДЕРОМ}
    \end{frame}
	
	
	\begin{frame}{ПРОГРЕСС НА 2026 ГОД}
		\begin{itemize}
			\item [-] Видимо, любую формализуемую задачу при достаточных вложениях машина может сделать в среднем не хуже, чем человек (пример: водить автомобиль)
			\item [-] окупаемость автоматизации приоритетнее сложности задачи (автоматический разработчик фронтенда выгоднее, чем автоматический дворник)
			\item [-] плохо формализуемые, но узкоспециальные ``интеллектуальные`` задачи - огромный прогресс за последние три года (машинный перевод, программирование)
			\item [-] под вопросом достижимость ``сильного`` ИИ в рамках текущих технологий
		\end{itemize}
	\end{frame}
	
	
	\begin{frame}{ТЕКУЩИЙ ПОДХОД ДЛЯ СЛОЖНЫХ ЗАДАЧ: БОЛЬШИЕ ЯЗЫКОВЫЕ (ВЕРОЯТНОСТНЫЕ) МОДЕЛИ}
		\begin{itemize}
		   \item [-] Машинное обучение огромного числа параметров на огромных наборах данных --- задача оптимизации
	       \item [-] ``всего лишь`` предсказывает вероятности следующего токена на основании предыдущих (контекста)
	       \item [-] (а у человека ``всего лишь`` распространяются импульсы по аксонам) 
	       \item [-] достаточно ли просто увеличивать сложность системы, чтобы она начала мыслить, как человек, или ``строительные материалы`` тоже важны?
	       \item [-] а если задача --- не ``как человек``, а ``лучше чем человек``?
	
        \end{itemize}
    \end{frame}
	
		\begin{frame}
		\frametitle{НАКОПЛЕННЫЕ ЧЕЛОВЕЧЕСТВОМ ДАННЫЕ}
		\begin{itemize}
			\item [-] anna’s archive: 1600TB включая нераспознанные
			\item [-] stackoverflow / stackexchange: несколько TB текста
			\item [-] arxiv.org: 6TB
			\item [-] Wikipedia: 200TB с медиафайлами
			\item [-] reddit: более 20TB с картинками
			
		\end{itemize}		
		
	\end{frame}

    \begin{frame}{КАК РАБОТАТЬ С ИИ-КОДЕРОМ}
	\begin{itemize}
		\item [-] это (пока) джуниор-программист, который программирует в 100 раз быстрее вас и знает все существующие (год назад) языки программирования, библиотеки и фреймворки
		\item [-] все инструменты коллективной разработки, позволяющие проекту выдержать попадание в него начинающего разработчика, давно существуют, просто теперь их внедрение стало абсолютно необходимым
		\item [-] даже тем, кто не планирует когда-либо разрабатывать ПО, именно ИИ-кодер наилучшим образом поможет с созданием профессиональной документации (языки разметки, диаграммы) или анализом табличных данных
	\end{itemize}
    \end{frame}	
    
    
    \begin{frame}{КАК РАБОТАТЬ С ИИ-КОДЕРОМ}
    	\begin{itemize}
    		\item [-] Планирование! (вайб-кодинг пусть подождет еще несколько лет). Либо режим планирования в вашей любимой CLI/IDE, либо запрос ``опиши последовательность шагов ии-кодеру для решения задачи`` к самой умной доступной нейросети
    		\item [-] Если план не нравится, добавляем детали и уточнения до тех пор, пока не получится хорошо
    		\item [-] План сохраняем в репозиторий как файл спецификации. Если появляются существенные дополнения, вносим в спецификацию. При выполнении каждого шага говорим кодеру, чтобы ознакомился с содержанием плана в целом.     	
    	\end{itemize}
    \end{frame}	

 \begin{frame}{КАК РАБОТАТЬ С ИИ-КОДЕРОМ}
	\begin{itemize}		
		\item [-] TDD: test driven development. Инструкцию для каждого шага снабжаем комментарием ``напиши тесты заранее`` 
		\item [-] Начинаем создание кода: один шаг - проверяемый результат. Если все работает, сохраняем ( \texttt{git commit} ) 
		\item [-] Если получилось совсем плохо, откатываем, улучшаем инструкцию, начинаем шаг с начала.
		\item [-] Если почти получилось, добавляем инструкции для коррекции или правим руками.
	\end{itemize}
\end{frame}	


    \begin{frame}{ЧТО НЕ НАДО СПРАШИВАТЬ У LLM}
	\begin{itemize}
		\item [-] сколько будет $9.11 - 9.1$? (лучше: напиши программу на Питоне для вычисления разности чисел и подставь значения)
		\item [-] вычисли $(\sin(x))'_x$ (лучше: чему равна производная синуса?)
				
	\end{itemize}
    \end{frame}	

    } %end section 1.1
    
    
    \section{1.2. Общение с LLM через OpenAI API}
    {
    	\begin{frame}
    		\centering
    		\vspace{2cm}
    		{\huge\headerfont\bfseries 1.2. ОБЩЕНИЕ С LLM ЧЕРЕЗ OpenAI API}
    	\end{frame}
    
    \begin{frame}{Qwen Code CLI Architecture}
    	
    	\centering
    	\begin{tikzpicture}[
    		blackbox/.style={
    			rectangle, draw=black, fill=black, text=white,
    			minimum width=3cm, minimum height=1.2cm,
    			align=center, rounded corners=2pt,
    			font=\small
    		},
    		whitebox/.style={
    			rectangle, draw=black, fill=white,
    			minimum width=2.2cm, minimum height=1cm,
    			align=center, font=\footnotesize
    		},
    		usercircle/.style={
    			circle, draw=black, fill=white,
    			minimum size=1.3cm, font=\footnotesize
    		},
    		arr/.style={-{Stealth[length=2.5mm]}, thick}
    		]
    		
    		% Black boxes
    		\node[blackbox] (llama) at (-3, 2) {\textbf{llama.cpp}\\model server};
    		\node[blackbox] (qwen) at (3, 2) {\textbf{Qwen code CLI}};
    		
    		% White box and circle
    		\node[usercircle] (user) at (0, -1) {User};
    		\node[whitebox] (fs) at (6, -1) {User's\\filesystem};
    		
    		% Bidirectional arrows between llama and qwen
    		\draw[arr] ([yshift=4pt]qwen.west) -- ([yshift=4pt]llama.east)
    		node[midway, above, font=\scriptsize] {context, requests};
    		\draw[arr] ([yshift=-4pt]llama.east) -- ([yshift=-4pt]qwen.west)
    		node[midway, below, font=\scriptsize] {thoughts, tool calls};
    		
    		% Arrow from qwen to user
    		\draw[arr] ($(qwen.south) + (-0.3, 0)$) -- ++(0, -0.8) -| (user.north);
    		\node[font=\scriptsize, left] at (1.35, 0.5) {responses};
    		
    		% Arrow from qwen to fs
    		\draw[arr] ($(qwen.south) + (0.3, 0)$) -- ++(0, -0.8) -| (fs.north);
    		\node[font=\scriptsize, right] at (4.65, 0.5) {changes};
    		
    	\end{tikzpicture}
    	
    \end{frame} 
    
    } %end section 1.2
     
\end{document}




